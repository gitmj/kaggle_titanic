{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 3-2 - Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For detailed steps on extracting and cleaning data, please review Sections 1-0 to 1-2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Extracting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../data/train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas - Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = df.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "age_mean = df['Age'].mean()\n",
    "df['Age'] = df['Age'].fillna(age_mean)\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n",
    "mode_embarked = mode(df['Embarked'])[0][0]\n",
    "df['Embarked'] = df['Embarked'].fillna(mode_embarked)\n",
    "\n",
    "df['Gender'] = df['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "\n",
    "pd.get_dummies(df['Embarked'], prefix='Embarked').head(10)\n",
    "df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "\n",
    "df = df.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols = [cols[1]] + cols[0:1] + cols[2:]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "\n",
    "train_data = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  PassengerId  Pclass        Age  SibSp  Parch     Fare  Gender  \\\n",
       "0         0            1       3  22.000000      1      0   7.2500       1   \n",
       "1         1            2       1  38.000000      1      0  71.2833       0   \n",
       "2         1            3       3  26.000000      0      0   7.9250       0   \n",
       "3         1            4       1  35.000000      1      0  53.1000       0   \n",
       "4         0            5       3  35.000000      0      0   8.0500       1   \n",
       "5         0            6       3  29.699118      0      0   8.4583       1   \n",
       "6         0            7       1  54.000000      0      0  51.8625       1   \n",
       "7         0            8       3   2.000000      3      1  21.0750       1   \n",
       "8         1            9       3  27.000000      0      2  11.1333       0   \n",
       "9         1           10       2  14.000000      1      0  30.0708       0   \n",
       "\n",
       "   Embarked_C  Embarked_Q  Embarked_S  \n",
       "0           0           0           1  \n",
       "1           1           0           0  \n",
       "2           0           0           1  \n",
       "3           0           0           1  \n",
       "4           0           0           1  \n",
       "5           0           1           0  \n",
       "6           0           0           1  \n",
       "7           0           0           1  \n",
       "8           0           0           1  \n",
       "9           1           0           0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  PassengerId  Pclass  Age  SibSp  Parch  Fare  Gender  Embarked_C  \\\n",
       "0         0            1       3   22      1      0  7.25       1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  \n",
       "0           0           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow - Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step #100, epoch #8, avg. train loss: 0.64138\n",
      "Step #200, epoch #16, avg. train loss: 0.60496\n",
      "Step #300, epoch #25, avg. train loss: 0.59895\n",
      "Step #400, epoch #33, avg. train loss: 0.59931\n",
      "Step #500, epoch #41, avg. train loss: 0.58970\n",
      "Step #600, epoch #50, avg. train loss: 0.58940\n",
      "Step #700, epoch #58, avg. train loss: 0.58570\n",
      "Step #800, epoch #66, avg. train loss: 0.57638\n",
      "Step #900, epoch #75, avg. train loss: 0.57474\n",
      "Step #1000, epoch #83, avg. train loss: 0.57221\n",
      "Step #1100, epoch #91, avg. train loss: 0.56770\n",
      "Step #1200, epoch #100, avg. train loss: 0.56261\n",
      "Step #1300, epoch #108, avg. train loss: 0.56148\n",
      "Step #1400, epoch #116, avg. train loss: 0.55801\n",
      "Step #1500, epoch #125, avg. train loss: 0.55661\n",
      "Step #1600, epoch #133, avg. train loss: 0.54321\n",
      "Step #1700, epoch #141, avg. train loss: 0.54437\n",
      "Step #1800, epoch #150, avg. train loss: 0.53698\n",
      "Step #1900, epoch #158, avg. train loss: 0.53476\n",
      "Step #2000, epoch #166, avg. train loss: 0.52711\n",
      "Step #2100, epoch #175, avg. train loss: 0.52387\n",
      "Step #2200, epoch #183, avg. train loss: 0.52280\n",
      "Step #2300, epoch #191, avg. train loss: 0.51298\n",
      "Step #2400, epoch #200, avg. train loss: 0.51379\n",
      "Step #2500, epoch #208, avg. train loss: 0.51190\n",
      "Step #2600, epoch #216, avg. train loss: 0.50962\n",
      "Step #2700, epoch #225, avg. train loss: 0.50177\n",
      "Step #2800, epoch #233, avg. train loss: 0.49841\n",
      "Step #2900, epoch #241, avg. train loss: 0.48763\n",
      "Step #3000, epoch #250, avg. train loss: 0.48860\n",
      "Step #3100, epoch #258, avg. train loss: 0.48110\n",
      "Step #3200, epoch #266, avg. train loss: 0.48562\n",
      "Step #3300, epoch #275, avg. train loss: 0.47725\n",
      "Step #3400, epoch #283, avg. train loss: 0.48171\n",
      "Step #3500, epoch #291, avg. train loss: 0.47615\n",
      "Step #3600, epoch #300, avg. train loss: 0.46980\n",
      "Step #3700, epoch #308, avg. train loss: 0.46753\n",
      "Step #3800, epoch #316, avg. train loss: 0.46894\n",
      "Step #3900, epoch #325, avg. train loss: 0.46261\n",
      "Step #4000, epoch #333, avg. train loss: 0.46248\n",
      "Step #4100, epoch #341, avg. train loss: 0.46308\n",
      "Step #4200, epoch #350, avg. train loss: 0.46606\n",
      "Step #4300, epoch #358, avg. train loss: 0.45757\n",
      "Step #4400, epoch #366, avg. train loss: 0.46112\n",
      "Step #4500, epoch #375, avg. train loss: 0.45919\n",
      "Step #4600, epoch #383, avg. train loss: 0.45386\n",
      "Step #4700, epoch #391, avg. train loss: 0.45213\n",
      "Step #4800, epoch #400, avg. train loss: 0.45355\n",
      "Step #4900, epoch #408, avg. train loss: 0.45203\n",
      "Step #5000, epoch #416, avg. train loss: 0.45146\n",
      "Step #5100, epoch #425, avg. train loss: 0.45379\n",
      "Step #5200, epoch #433, avg. train loss: 0.44992\n",
      "Step #5300, epoch #441, avg. train loss: 0.44933\n",
      "Step #5400, epoch #450, avg. train loss: 0.45408\n",
      "Step #5500, epoch #458, avg. train loss: 0.44746\n",
      "Step #5600, epoch #466, avg. train loss: 0.45237\n",
      "Step #5700, epoch #475, avg. train loss: 0.44752\n",
      "Step #5800, epoch #483, avg. train loss: 0.44672\n",
      "Step #5900, epoch #491, avg. train loss: 0.44542\n",
      "Step #6000, epoch #500, avg. train loss: 0.44669\n",
      "Step #6100, epoch #508, avg. train loss: 0.44774\n",
      "Step #6200, epoch #516, avg. train loss: 0.44709\n",
      "Step #6300, epoch #525, avg. train loss: 0.44048\n",
      "Step #6400, epoch #533, avg. train loss: 0.44216\n",
      "Step #6500, epoch #541, avg. train loss: 0.44443\n",
      "Step #6600, epoch #550, avg. train loss: 0.44010\n",
      "Step #6700, epoch #558, avg. train loss: 0.43991\n",
      "Step #6800, epoch #566, avg. train loss: 0.44250\n",
      "Step #6900, epoch #575, avg. train loss: 0.44430\n",
      "Step #7000, epoch #583, avg. train loss: 0.43922\n",
      "Step #7100, epoch #591, avg. train loss: 0.43992\n",
      "Step #7200, epoch #600, avg. train loss: 0.43587\n",
      "Step #7300, epoch #608, avg. train loss: 0.43563\n",
      "Step #7400, epoch #616, avg. train loss: 0.44106\n",
      "Step #7500, epoch #625, avg. train loss: 0.43945\n",
      "Step #7600, epoch #633, avg. train loss: 0.43479\n",
      "Step #7700, epoch #641, avg. train loss: 0.43858\n",
      "Step #7800, epoch #650, avg. train loss: 0.43606\n",
      "Step #7900, epoch #658, avg. train loss: 0.43797\n",
      "Step #8000, epoch #666, avg. train loss: 0.42926\n",
      "Step #8100, epoch #675, avg. train loss: 0.43367\n",
      "Step #8200, epoch #683, avg. train loss: 0.43306\n",
      "Step #8300, epoch #691, avg. train loss: 0.43142\n",
      "Step #8400, epoch #700, avg. train loss: 0.43204\n",
      "Step #8500, epoch #708, avg. train loss: 0.43521\n",
      "Step #8600, epoch #716, avg. train loss: 0.42824\n",
      "Step #8700, epoch #725, avg. train loss: 0.43175\n",
      "Step #8800, epoch #733, avg. train loss: 0.43233\n",
      "Step #8900, epoch #741, avg. train loss: 0.43302\n",
      "Step #9000, epoch #750, avg. train loss: 0.42848\n",
      "Step #9100, epoch #758, avg. train loss: 0.42898\n",
      "Step #9200, epoch #766, avg. train loss: 0.42844\n",
      "Step #9300, epoch #775, avg. train loss: 0.42804\n",
      "Step #9400, epoch #783, avg. train loss: 0.43300\n",
      "Step #9500, epoch #791, avg. train loss: 0.42037\n",
      "Step #9600, epoch #800, avg. train loss: 0.42725\n",
      "Step #9700, epoch #808, avg. train loss: 0.42147\n",
      "Step #9800, epoch #816, avg. train loss: 0.42781\n",
      "Step #9900, epoch #825, avg. train loss: 0.42628\n",
      "Step #10000, epoch #833, avg. train loss: 0.42315\n"
     ]
    }
   ],
   "source": [
    "import skflow\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "random.seed(42) # to sample data the same way\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_data[:800, 2:], train_data[:800, 0], test_size=0.1, random_state=42)\n",
    "\n",
    "# To set up custom decay, set learning_rate = <custom-function-name> when calling TensorFlowEstimator()\n",
    "def exp_decay(global_step):\n",
    "    return tf.train.exponential_decay(\n",
    "        learning_rate=0.01, global_step=global_step,\n",
    "        decay_steps=2, decay_rate=0.001)\n",
    "def my_model(X, y):\n",
    "    layers = skflow.ops.dnn(X, [40, 20, 10])\n",
    "    return skflow.models.logistic_regression(layers, y)\n",
    "\n",
    "# model = skflow.TensorFlowDNNClassifier(hidden_units=[20, 40, 10], n_classes=2, batch_size=128, steps=1000,\n",
    "#                                       learning_rate=0.05)\n",
    "model = skflow.TensorFlowEstimator(model_fn=my_model, n_classes=2, batch_size=64, steps=10000, learning_rate=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "model.save('/tmp/tf_examples/my_model_1/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow - Making predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy\n",
      "0.826388888889\n",
      "Test accuracy\n",
      "0.8125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print ('Train accuracy')\n",
    "print(accuracy_score(model.predict(X_train), y_train))\n",
    "\n",
    "\n",
    "print ('Test accuracy')\n",
    "print(accuracy_score(model.predict(X_test), y_test))\n",
    "\n",
    "# X_test.shape\n",
    "\n",
    "# y_test = train_data[800:, 0]\n",
    "# y_prediction = model.predict(train_data[800:, 2:])\n",
    "# print accuracy_score(y_prediction, y_test)\n",
    "#print \"prediction accuracy:\", np.sum(y_test == y_prediction)*1./len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare output of submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Pclass   Age  SibSp  Parch     Fare  Gender  Embarked_C  \\\n",
      "0          892       3  34.5      0      0   7.8292       1           0   \n",
      "1          893       3  47.0      1      0   7.0000       0           0   \n",
      "2          894       2  62.0      0      0   9.6875       1           0   \n",
      "3          895       3  27.0      0      0   8.6625       1           0   \n",
      "4          896       3  22.0      1      1  12.2875       0           0   \n",
      "5          897       3  14.0      0      0   9.2250       1           0   \n",
      "6          898       3  30.0      0      0   7.6292       0           0   \n",
      "7          899       2  26.0      1      1  29.0000       1           0   \n",
      "8          900       3  18.0      0      0   7.2292       0           1   \n",
      "9          901       3  21.0      2      0  24.1500       1           0   \n",
      "\n",
      "   Embarked_Q  Embarked_S  \n",
      "0           1           0  \n",
      "1           0           1  \n",
      "2           1           0  \n",
      "3           0           1  \n",
      "4           0           1  \n",
      "5           0           1  \n",
      "6           1           0  \n",
      "7           0           1  \n",
      "8           0           0  \n",
      "9           0           1  \n",
      "(418, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mjtiwari/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:9: FutureWarning: scalar indexers for index type Int64Index should be integers and not floating point\n"
     ]
    }
   ],
   "source": [
    "df_test = pd.read_csv('../data/test.csv')\n",
    "\n",
    "df_test = df_test.drop(['Name', 'Ticket', 'Cabin'], axis=1)\n",
    "\n",
    "df_test['Age'] = df_test['Age'].fillna(age_mean)\n",
    "\n",
    "fare_means = df.pivot_table('Fare', index='Pclass', aggfunc='mean')\n",
    "df_test['Fare'] = df_test[['Fare', 'Pclass']].apply(lambda x:\n",
    "                            fare_means[x['Pclass']] if pd.isnull(x['Fare'])\n",
    "                            else x['Fare'], axis=1)\n",
    "\n",
    "df_test['Gender'] = df_test['Sex'].map({'female': 0, 'male': 1}).astype(int)\n",
    "df_test = pd.concat([df_test, pd.get_dummies(df_test['Embarked'], prefix='Embarked')],\n",
    "                axis=1)\n",
    "\n",
    "df_test = df_test.drop(['Sex', 'Embarked'], axis=1)\n",
    "\n",
    "print df_test.head(10)\n",
    "print df_test.shape\n",
    "\n",
    "test_data = df_test.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#output = model_linear_regression.predict(test_data[:, 1:])\n",
    "output = model.predict(test_data[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = np.c_[test_data[:,0].astype(int), output.astype(int)]\n",
    "df_result = pd.DataFrame(result[:,0:2], columns=['PassengerId', 'Survived'])\n",
    "df_result.to_csv('../results/titanic_3-3.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix: Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Mac:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pip install https://storage.googleapis.com/tensorflow/mac/tensorflow-0.5.0-py2-none-any.whl\n",
    "pip install git+git://github.com/google/skflow.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Ubuntu:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "pip install https://storage.googleapis.com/tensorflow/linux/cpu/tensorflow-0.5.0-cp27-none-linux_x86_64.whl\n",
    "pip install git+git://github.com/google/skflow.git"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
